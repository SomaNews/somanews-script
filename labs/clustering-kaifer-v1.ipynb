{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline script of SomaNews Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import hanja\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cnouns\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Data\n",
    "Load Data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120835, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../datastore/whole_articles.p\")\n",
    "df = df.drop(['author', 'link', 'imageURL'], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "1. Remove stopwords (regex, hanja)\n",
    "2. POS Tagging with KoNLPy, Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    text = hanja.translate(text, 'substitution')\n",
    "    text = re.sub(u'(\\[.*\\]|\\(.*\\))', '', text)\n",
    "    text = re.sub(u'(\\(|\\)|\\[|\\])', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['clean_title'] = [text_cleaning(t) for t in train_df.title]\n",
    "train_df['clean_content'] = [text_cleaning(t) for t in train_df.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['tokenized_title'] = [cnouns.tokenize(t) for t in train_df.clean_title]\n",
    "train_df['tokenized_content'] = [cnouns.tokenize(t) for t in train_df.clean_content]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"../datastore/w-preprocesse.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../datastore/preprocesse.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "# title_flat = [item for sublist in titles for item in sublist]\n",
    "x_list = vectorizer.fit_transform(train_df.tokenized_title + train_df.tokenized_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x_list.toarray())\n",
    "print(dict(zip(vectorizer.get_feature_names(), vectorizer._tfidf.idf_)))\n",
    "# x_list.stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Models\n",
    "1. Tf-idf and Cosine similarity\n",
    "2. K-Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x_list):\n",
    "    dist = 1 - cosine_similarity(x_list)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_clusters = len(topics)\n",
    "num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "km = KMeans(n_clusters=num_clusters, n_jobs=-1)\n",
    "km.fit(x_list)\n",
    "clusters = km.labels_.tolist()\n",
    "print(\"Done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(clusters), len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_cluster_topic(is_cluster):\n",
    "    if(is_cluster):\n",
    "        print(\"Cluster -> Topic\")\n",
    "        criteria = 'cluster'\n",
    "        target = 'topic_idx'\n",
    "    else:\n",
    "        print(\"Topic -> Cluster\")\n",
    "        criteria = 'topic_idx'\n",
    "        target = 'cluster'\n",
    "        \n",
    "    total_doc = 0    \n",
    "    total_accuracy = 0    \n",
    "    for i in range(0, num_clusters):\n",
    "        criteria_set = train_df[train_df[criteria]==i]\n",
    "        target_count = {}\n",
    "        for j in range(0, num_clusters):\n",
    "            target_set = criteria_set[criteria_set[target]==j]\n",
    "            target_count[j] = len(target_set)\n",
    "        max_target_idx = max(target_count.iteritems(), key=operator.itemgetter(1))[0]\n",
    "        accuracy = 100*target_count[max_target_idx]/float(len(criteria_set))\n",
    "        total_accuracy = total_accuracy + accuracy\n",
    "        if(is_cluster):\n",
    "            topic_str = topics[max_target_idx]\n",
    "        else:\n",
    "            topic_str = topics[i]\n",
    "        print(\"#%d -> #%d Accuracy is %.4d/%.4d = %.10f \\t %s\" % (i, max_target_idx, target_count[max_target_idx], len(criteria_set), accuracy, topic_str))\n",
    "        total_doc = total_doc + target_count[max_target_idx]\n",
    "        \n",
    "    print(\"%.4f\" % (total_accuracy/num_clusters))\n",
    "    print(\"%.4f\" % (100 * total_doc/len(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in topics:\n",
    "    topic = topics[idx]\n",
    "    print(\"%.4d - %s\" % (len(train_df[train_df.topic==topic]), topic)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match_cluster_topic(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_cluster_topic(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_top_words(km, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjusted_rand_score(train_df.topic, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(train_df.topic, n_folds=3)\n",
    "cross_val_score(km, x_list, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = train_df.drop(['_id', 'content', 'description', 'provider', 'providerNewsID', 'publishedAt'], axis=1)\n",
    "two = df[df.cluster==3]\n",
    "# two[two.topic_idx==4]\n",
    "for idx in topics:\n",
    "    print topics[idx], len(two[two.topic_idx==idx])\n",
    "# two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cartesian = itertools.product(range(num_clusters), range(num_clusters))\n",
    "\n",
    "temp = {\n",
    "    'cluster': [],\n",
    "    'topic_idx': [],\n",
    "    'counts': []\n",
    "}\n",
    "for c, t in cartesian:\n",
    "    clusters = df[df.cluster==c]\n",
    "    topics = clusters[clusters.topic_idx==t]\n",
    "    temp['cluster'].append(c)\n",
    "    temp['topic_idx'].append(t)\n",
    "    temp['counts'].append(len(topics))\n",
    "    \n",
    "results = pd.DataFrame(temp)\n",
    "results = results[results.counts!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# results[results.counts!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(results.topic_idx, results.cluster, 'ro')\n",
    "for index, row in results.iterrows():\n",
    "    x = row['topic_idx']\n",
    "    y = row['cluster']\n",
    "    ax.annotate('  %d' % row['counts'], xy=(x,y), textcoords='data')\n",
    "plt.axis([-1, 7, -1, 7])\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Cluster')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
