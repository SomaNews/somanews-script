{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import math\n",
    "import hanja\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cnouns as cn\n",
    "import check_utils as cu\n",
    "import deep_utils as du\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim import models\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "import cPickle as pickle\n",
    "from spherecluster import SphericalKMeans\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Articles = namedtuple('Articles', 'words tags split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = 1\n",
    "test = 2\n",
    "\n",
    "times = {\n",
    "    \"preprocessing\": {},\n",
    "    \"learning\": {},\n",
    "    \"clustering\": {},\n",
    "    \"similarity\": {},\n",
    "    \"topic\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(test==1):\n",
    "    topics = {\n",
    "          0: u'올림픽',\n",
    "          1: u'테러', \n",
    "          2: u'브렉시트', \n",
    "          3: u'미국 금리',\n",
    "          4: u'바이러스', \n",
    "          5: u'미국대선,힐러리,트럼프', \n",
    "          6: u'시리아 전쟁, 난민'\n",
    "         }\n",
    "    train_df = pd.read_pickle(\"../datastore/international.p\")\n",
    "    num_clusters = len(topics)\n",
    "elif(test==2):    \n",
    "    train_df = pd.read_pickle(\"../datastore/weekly_2.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times[\"preprocessing\"][\"start\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['target_str'] = [cn.tokenize(row.title + \" \" + row.content) for idx, row in train_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = len(train_df) / 4\n",
    "print size, len(train_df), size * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldocs = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    tokens = row['target_str'].split(' ')\n",
    "    words = tokens[0:]\n",
    "    tags = [idx]\n",
    "    tmp = idx//size % 4\n",
    "    split = ['train','test','extra','extra'][tmp]  # 25k train, 25k test, 25k extra\n",
    "    alldocs.append(Articles(words, tags, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"preprocessing\"][\"end\"] = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"learning\"][\"start\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_models = [\n",
    "    # PV-DM Distributed Momory Model of PV\n",
    "    # w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW Distributed Bag of Words version of PV\n",
    "    Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_models[0].load_word2vec_format(\"../datastore/sejongcorpus_w2v.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_models[0].build_vocab(alldocs)\n",
    "print simple_models[0]\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print(model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_list = alldocs[:]\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # shuffling gets best results\n",
    "\n",
    "    for name, train_model in models_by_name.items():\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        train_model.train(doc_list)\n",
    "        print(\"%i passes : %s\" % (epoch + 1, name))\n",
    "\n",
    "    print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"learning\"][\"end\"] = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"../datastore/deep_df.p\")\n",
    "\n",
    "models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)'].save(\"../datastore/d2v-dmc_%d.p\" % test)\n",
    "models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'].save(\"../datastore/d2v-dbow_%d.p\" % test)\n",
    "models_by_name['Doc2Vec(dm/m,d100,n5,w10,mc2,t8)'].save(\"../datastore/d2v-dmm_%d.p\" % test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'], models_by_name['Doc2Vec(dm/m,d100,n5,w10,mc2,t8)']])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'], models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dm = models_by_name['dbow+dmm']\n",
    "# dm = models_by_name['dbow+dmc']\n",
    "dm = models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_arr = dm.docvecs\n",
    "inp = np.array(doc_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KMeans\n",
    "# model = SphericalKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "best_k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for k in range(50, 60):\n",
    "#     t_km = model(n_clusters=k, n_jobs=-1).fit(inp)\n",
    "#     score = silhouette_score(inp, t_km.labels_)\n",
    "#     if best_score < score:\n",
    "#         best_score = score\n",
    "#         best_k = k\n",
    "#     print(\"In Clusters =\", k, \", Score is : %0.3f\" % score)\n",
    "# print(\"In Clusters =\", best_k, \", Best score is : %0.3f\" % best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"clustering\"][\"start\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cluster = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_km = model(n_clusters=n_cluster, n_jobs=-1)\n",
    "d_km.fit(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = d_km.labels_.tolist()\n",
    "train_df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"clustering\"][\"end\"] = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"inertia : \", d_km.inertia_\n",
    "print \"silhouette score : \", silhouette_score(inp, d_km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_cluster = cu.sort_count(train_df, range(n_cluster))\n",
    "sorted_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_cluster_idx = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "center_idx = cu.find_center_article(d_km, target_cluster_idx, inp)\n",
    "print center_idx, train_df.loc[center_idx].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_cluster = train_df[train_df.cluster==target_cluster_idx]\n",
    "print \"size \", len(target_cluster)\n",
    "target_cluster.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dm.docvecs.similarity(d1=2183, d2=2165)\n",
    "print dm.docvecs.similarity(d1=2267, d2=2328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cu.test_similar(1, dm.docvecs, train_df, threadsold=0.5, is_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"similarity\"][\"start\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = du.similarity_clustering(train_df, dm.docvecs, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"similarity\"][\"end\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"../datastore/deep_result_df.p\")\n",
    "pickle.dump(centers, open(\"../datastore/deep_centers.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = du.similarity_iner_score(centers, train_df, dm.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_1 = scores[scores.cnt==1]\n",
    "countby = scores[scores.cnt>10]\n",
    "print \"total:\", len(scores), \", size_1:\",len(size_1), \", countby:\", len(countby)\n",
    "ss = countby.sum(axis=0)\n",
    "print \"distance:\", ss['distance'] * 100\n",
    "print \"variance:\", ss['variance']\n",
    "print \"similarity:\", (ss['similarity'] * 100)/len(countby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times[\"topic\"][\"start\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = du.get_all_topics(train_df, countby.cluster.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[\"topic\"][\"end\"] = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(topics, open(\"../datastore/deep_topics.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in times.iteritems():\n",
    "    value[\"elapsed\"]= value[\"end\"] - value[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(times, open(\"../datastore/deep_times.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
