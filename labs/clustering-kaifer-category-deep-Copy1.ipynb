{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import math\n",
    "import hanja\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cnouns as cn\n",
    "import check_utils as cu\n",
    "import deep_utils as du\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim import models\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "import cPickle as pickle\n",
    "from spherecluster import SphericalKMeans\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Articles = namedtuple('Articles', 'words tags split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = 1\n",
    "test = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(test==1):\n",
    "    topics = {\n",
    "          0: u'올림픽',\n",
    "          1: u'테러', \n",
    "          2: u'브렉시트', \n",
    "          3: u'미국 금리',\n",
    "          4: u'바이러스', \n",
    "          5: u'미국대선,힐러리,트럼프', \n",
    "          6: u'시리아 전쟁, 난민'\n",
    "         }\n",
    "    train_df = pd.read_pickle(\"../datastore/international.p\")\n",
    "    num_clusters = len(topics)\n",
    "elif(test==2):    \n",
    "    train_df = pd.read_pickle(\"../datastore/weekly_2.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_t_preprocessing = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['target_str'] = [cn.tokenize(row.title + \" \" + row.content) for idx, row in train_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = len(train_df) / 4\n",
    "print size, len(train_df), size * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldocs = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    tokens = row['target_str'].split(' ')\n",
    "    words = tokens[0:]\n",
    "    tags = [idx]\n",
    "    tmp = idx//size % 4\n",
    "    split = ['train','test','extra','extra'][tmp]  # 25k train, 25k test, 25k extra\n",
    "    alldocs.append(Articles(words, tags, split))\n",
    "doc_list = alldocs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_t_preprocessing = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_t_learning = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_models = [\n",
    "    # PV-DM Distributed Momory Model of PV\n",
    "    # w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW Distributed Bag of Words version of PV\n",
    "    Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_models[0].load_word2vec_format(\"../datastore/w-w2v.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_models[0].build_vocab(alldocs)\n",
    "print simple_models[0]\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print(model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # shuffling gets best results\n",
    "\n",
    "    for name, train_model in models_by_name.items():\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        train_model.train(doc_list)\n",
    "        print(\"%i passes : %s\" % (epoch + 1, name))\n",
    "\n",
    "    print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_t_learning = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save or Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"../datastore/deep_df.p\")\n",
    "\n",
    "models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)'].save(\"../datastore/d2v-dmc_%d.p\" % test)\n",
    "models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'].save(\"../datastore/d2v-dbow_%d.p\" % test)\n",
    "models_by_name['Doc2Vec(dm/m,d100,n5,w10,mc2,t8)'].save(\"../datastore/d2v-dmm_%d.p\" % test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../datastore/deep_df.p\")\n",
    "\n",
    "models_by_name = OrderedDict()\n",
    "models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)'] = Doc2Vec.load(\"../datastore/d2v-dmc_%d.p\" % test)\n",
    "models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'] = Doc2Vec.load(\"../datastore/d2v-dbow_%d.p\" % test)\n",
    "models_by_name['Doc2Vec(dm/m,d100,n5,w10,mc2,t8)'] = Doc2Vec.load(\"../datastore/d2v-dmm_%d.p\" % test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'], models_by_name['Doc2Vec(dm/m,d100,n5,w10,mc2,t8)']])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([models_by_name['Doc2Vec(dbow,d100,n5,mc2,t8)'], models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dm = models_by_name['dbow+dmm']\n",
    "# dm = models_by_name['dbow+dmc']\n",
    "dm = models_by_name['Doc2Vec(dm/c,d100,n5,w5,mc2,t8)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_arr = dm.docvecs\n",
    "inp = np.array(doc_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KMeans\n",
    "# model = SphericalKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "best_k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(50, 60):\n",
    "    t_km = model(n_clusters=k, n_jobs=-1).fit(inp)\n",
    "    score = silhouette_score(inp, t_km.labels_)\n",
    "    if best_score < score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "    print(\"In Clusters =\", k, \", Score is : %0.3f\" % score)\n",
    "print(\"In Clusters =\", best_k, \", Best score is : %0.3f\" % best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cluster = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_km = model(n_clusters=n_cluster, n_jobs=-1)\n",
    "d_km.fit(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = d_km.labels_.tolist()\n",
    "train_df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"inertia : \", d_km.inertia_\n",
    "print \"silhouette score : \", silhouette_score(inp, d_km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_cluster = cu.sort_count(train_df, range(n_cluster))\n",
    "sorted_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_cluster_idx = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "center_idx = cu.find_center_article(d_km, target_cluster_idx, inp)\n",
    "print center_idx, train_df.loc[center_idx].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_cluster = train_df[train_df.cluster==target_cluster_idx]\n",
    "print \"size \", len(target_cluster)\n",
    "target_cluster.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dm.docvecs.similarity(d1=2183, d2=2165)\n",
    "print dm.docvecs.similarity(d1=2267, d2=2328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cu.test_similar(1, dm.docvecs, train_df, threadsold=0.5, is_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = du.similarity_clustering(train_df, dm.docvecs, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"../datastore/deep_result_df.p\")\n",
    "pickle.dump(centers, open(\"../datastore/deep_centers.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../datastore/deep_result_df.p\")\n",
    "centers = pickle.load(open(\"../datastore/deep_centers.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = du.similiarity_iner_score(centers, train_df, dm.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 997 , size_1: 808 , countby: 22\n",
      "distance: 21712.8087121\n",
      "variance: 4.32924858294\n",
      "similarity: 80.1201240607\n"
     ]
    }
   ],
   "source": [
    "size_1 = score[score.cnt==1]\n",
    "countby = score[score.cnt>10]\n",
    "print \"total:\", len(score), \", size_1:\",len(size_1), \", countby:\", len(countby)\n",
    "ss = countby.sum(axis=0)\n",
    "print \"distance:\", ss['distance'] * 100\n",
    "print \"variance:\", ss['variance']\n",
    "print \"similarity:\", (ss['similarity'] * 100)/len(countby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.sort_values('similarity', ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.sort_values('cnt', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countby.sort_values('similarity', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cluster : 22\n",
      "progress - 0 / 22\n",
      "progress - 1 / 22\n",
      "progress - 2 / 22\n",
      "progress - 3 / 22\n",
      "progress - 4 / 22\n",
      "progress - 5 / 22\n",
      "progress - 6 / 22\n",
      "progress - 7 / 22\n",
      "progress - 8 / 22\n",
      "progress - 9 / 22\n",
      "progress - 10 / 22\n",
      "progress - 11 / 22\n",
      "progress - 12 / 22\n",
      "progress - 13 / 22\n",
      "progress - 14 / 22\n",
      "progress - 15 / 22\n",
      "progress - 16 / 22\n",
      "progress - 17 / 22\n",
      "progress - 18 / 22\n",
      "progress - 19 / 22\n",
      "progress - 20 / 22\n",
      "progress - 21 / 22\n"
     ]
    }
   ],
   "source": [
    "topics = du.get_all_topics(train_df, countby.cluster.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(topics, open(\"../datastore/deep_topics.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = pickle.load(open(\"../datastore/deep_topics.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         2\n",
       "2       111\n",
       "3        90\n",
       "4        66\n",
       "13      162\n",
       "17       24\n",
       "18      688\n",
       "21       42\n",
       "43      180\n",
       "44      817\n",
       "48       80\n",
       "54      145\n",
       "55      361\n",
       "57      210\n",
       "68      122\n",
       "69     2145\n",
       "70     1159\n",
       "73     1622\n",
       "85     1026\n",
       "104     709\n",
       "106     580\n",
       "129     252\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countby.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 대표NNG 누리NNG 호남NNG\n",
      " 대표NNG 경제NNG 추NNG대표NNG\n",
      " 대표NNG 의원NNG 국회NNG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4          [사설] 경제 앞길 막은 야당이 경제 失政 비판할 자격 있나\n",
       "68       [플라자] 대한민국ROTC중앙회, 나라 사랑 조찬 포럼 개최 외\n",
       "111                  증세카드 꺼낸 野대표 \"법인세 정상화해야\"\n",
       "112               국감에 부를 증인 4100명 넘어 최대규모 될듯\n",
       "113                      혹평한 국민의黨 \"집권당처럼 행동\"\n",
       "114                     호평해준 새누리 \"민생 집중한 연설\"\n",
       "115                          '창조경제센터 동물원' 공방\n",
       "116                  이정현 \"김대중 정부때 반대만 한것 사과\"\n",
       "118                 문재인 \"한진해운 일시적 국유화까지 검토를\"\n",
       "132                [사설] 여당 대표 입에서도 나온 \"國害의원\"\n",
       "134           [류근일 칼럼] 있지만 없는 '제3의 길' '제3지대'\n",
       "229               DJ·盧에 사과한 與대표 \"호남·새누리 손잡자\"\n",
       "230        김재수, 장관 되니 딴소리… \"청문회 때 흙수저라 무시당해\"\n",
       "263          [사설] 나라 사방이 다 막혔는데 大選 경쟁은 벌써 열기\n",
       "280     [TV조선 주중 하이라이트] '정두언·김유정의 이것이 정치다' 외\n",
       "372         직접 운전·페이스북 동영상… 與 주자들은 조심스레 '꿈틀'\n",
       "373               오죽했으면… 文, 지지자들에 \"선플 좀 답시다\"\n",
       "374           문재인·김부겸, 팬클럽 勢몰이… 안철수, 창조경제 비판\n",
       "551      [플라자] 한국문학교육학회 창립 20주년 기념 학술대회 개최 외\n",
       "583                              속으로 웃는 국민의黨\n",
       "585                      光州로 달려간 野지도부와 대선주자들\n",
       "587                    국회 정상화에 서청원 의원이 막후 역할\n",
       "590                     南美 다녀온 최경환 \"포퓰리즘 경계\"\n",
       "591                   독일 가는 안철수 \"선진 경제 배우겠다\"\n",
       "721                100일간의 정기국회… 대선 앞둬 곳곳 지뢰밭\n",
       "723               김종인에 사과한 추미애 \"수시로 고견 여쭙겠다\"\n",
       "724          黨대표가 \"복당 문제없다\"는데… 자리 박찬 親朴 최고위원\n",
       "726                    문재인 \"김부겸·안희정 출마선언 환영\"\n",
       "728                  안철수, 지난달 28일 손학규와 단독 회동\n",
       "731                  조윤선 청문회 파행… 靑, 임명 진행할 듯\n",
       "                        ...                 \n",
       "1361                        아무 일도 안한 정기국회 첫날\n",
       "1368                  ‘우병우 청문회’될 운영위… 곳곳 지뢰밭\n",
       "1374                  “복당 성급” 최고위회의 자리박찬 이장우\n",
       "1376                 김종인 만난 추미애 “고견 자주 여쭙겠다”\n",
       "1377                   안철수 8월 28일 강진서 손학규 면담\n",
       "1378                 김부겸 이어 안희정도 사실상 대선출마 선언\n",
       "1586                박지원 “박근혜 대통령이 모든 문제의 시작”\n",
       "1616             이정현 대표 맞은 이희호 “세월호 관심 가져달라”\n",
       "1630           이재명 “우리사회 혁명적 변화 요구”…대선 출마 밝혀\n",
       "1633            추미애 “야당도 양보하겠다”…민생경제 영수회담 제안\n",
       "1729       정진석 “야3당, 김재수 해임건의 발의는 국정방해·국정마비”\n",
       "1745                    송영길 “호남-새누리 연대? 글쎄…”\n",
       "1751             추미애 더민주 대표 “비상민생경제 영수회담” 제안\n",
       "1753         노회찬 “새누리당, 단독 집권 어려워 호남에 연대 제안”\n",
       "1813      “더민주 대선 경선 내년 6월까지” vs  “그렇게는 못한다”\n",
       "1815                   이정현 “호남-새누리당 연대정치 가능”\n",
       "1895        이정현 청년수당 비난에, 서울시 “집권당 대표가 할 일?”\n",
       "1971                     김종인, 경제민주화 연구조직 만든다\n",
       "1972                            야권, 문재인을 넘어라\n",
       "1973         정기국회 ‘전운’ 고조… 노동·검찰개혁 등 곳곳 ‘지뢰’\n",
       "1974                            여권, 반기문을 넘어라\n",
       "2087                   손학규 “죽음 각오하고 저를 던지겠다”\n",
       "2159                      김광진 “안희정 돌풍 상당할 것”\n",
       "2162          광주 찾은 안희정 “불공정한 구조를 바꾸는 정치하겠다”\n",
       "2175     광주 간 안희정 “호남·김대중 정신이 내 도전에 큰 힘 될 것”\n",
       "2181         박지원, “새누리당 의원들 음주·고성…야당 연습하는 것”\n",
       "2182     추미애 ”우병우 ‘우’자에 경기…무책임한 새누리 꾸짖을 수밖에”\n",
       "2229                    ‘불펜투수’ 안희정, 마운드에 오르다\n",
       "2279                추미애 광주서 ‘호남민심 되돌리기’ 1박2일\n",
       "2300                     안철수-손학규, 강진 토담집서 만나\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_idx = 111\n",
    "du.topic_print(topics[cluster_idx])\n",
    "train_df[train_df.cluster==cluster_idx].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
