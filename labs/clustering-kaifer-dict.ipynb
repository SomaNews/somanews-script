{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SimilarityClustering import SimilarityClustering\n",
    "import articles_data\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cnouns as cn\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/somanews')\n",
    "client.somanews.authenticate('ssomanews', 'ssomanews1029')\n",
    "db = client.get_database('somanews')\n",
    "\n",
    "crawled_collection = db.get_collection('crawledArticles')\n",
    "clusters_collection = db.get_collection('clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catelist_path = '../datastore/category2.p'\n",
    "# w2v_src_dir = \"../datastore/w2v_src\"\n",
    "# w2v_path = \"../datastore/sejongcorpus_w2v2.p\"\n",
    "\n",
    "w2v_src_dir = \"../datastore/w2v_src2\"\n",
    "w2v_path = \"../datastore/sejongcorpus_w2v2_2.p\"\n",
    "\n",
    "corpus_path = \"../datastore/corpus2.p\"\n",
    "now = datetime.now()\n",
    "prefix = int(\"%.2d%.2d\"%(now.month, now.day))\n",
    "prefix = 1104\n",
    "prefix_str = \"%d_00\" % prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict\n",
    "* 세종코퍼스에서 고유명사 뽑기\n",
    "* Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import articles_data\n",
    "import cnouns as cn\n",
    "\n",
    "headline_path = '../datastore/headline2.p'\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = articles_data.remove_headlines(text, headline_path)\n",
    "    return cn.tokenizer(text)\n",
    "\n",
    "print tokenizer(u\"[사설]박근혜 대통령은\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import hanja\n",
    "import re\n",
    "import cnouns as cn\n",
    "\n",
    "from HuffmanCoding import HuffmanCoding\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# t1 = train_df.publishedAt[0]\n",
    "# t2 = train_df.publishedAt[2]\n",
    "\n",
    "# (now - t2).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = articles_data.find_recent_articles(crawled_collection, catelist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_df.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp_str = u'새누리당과 새누리당 박근혜 대통령은 8일 \"국회에서 여야 합의로 총리에 좋은 분을 추천해 주신다면 그 분을 총리로 임명해 실질적으로 내각을 통할할 수 있도록 하겠다\"고 밝혔다. 박 대통령은 이날 오전 국회를 전격 방문, 정세균 국회의장을 만나 최순실 정국수습을 위해 국회가 추천한 총리를 임명해달라는 야권의 요구를 수용하겠다는 의사를 공식적으로 밝혔다. 이에 따라 박 대통령은 지난 2일 참여정부 핵심인사였던 김병준 전 청와대 정책실장을 책임 총리로 내정했으나, 지명 6일 만에 사실상 철회하는 수순을 밟을 것으로 예상된다. 박 대통령이 정기국회 예산안 시정연설이나 국회 개원연설 등 공식 일정을 제외하고 정치적인 이유로 국회를 방문한 것은 이번이 두번째다. 박 대통령은 지난 2013년 9월 국정원 대선개입 의혹 정국을 풀기 위해 여야 대표와 국회 사랑재에서 회동한 적이 있다.'\n",
    "# inp_str = u'새누리당 더민주 핵심인사 참여정부, 새천년 새누리당은 새누리당이 새누리당과'\n",
    "# inp_str = train_df.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_text = cn.text_cleaning_without_special_ch(inp_str)\n",
    "syllables = cn.tokenize_syllables(7, clean_text)\n",
    "morphs = mecab.morphs(clean_text)\n",
    "nouns = mecab.nouns(clean_text)\n",
    "pos_tags = [m for m in morphs if m not in nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hc = HuffmanCoding(clean_text)\n",
    "huff_dict = hc.encode()\n",
    "hcd = hc.decode(syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = hcd[hcd.apply(lambda x: not x['word'] in pos_tags, axis=1)]\n",
    "sortby_word = filtered.sort_values('word', ascending=True)\n",
    "sortby_weight = filtered.sort_values('weight', ascending=False)\n",
    "# sortby_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicts = [u'새누리', u'새누리당', u'더민주', u'더민주당', u'최순실', u'박대통령', u'국회의장', u'야권의요구', u'정기국회', u'참여정부']\n",
    "def tokenizer(inp_str):\n",
    "    return cn.custom_pos_tags(inp_str, dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새누리당NNP 과JC 새누리당NNP 박근혜NNP 대통령NNG 은JX 8SN 일NNBC 국회NNG 에서JKB 여야NNG 합의NNG 로JKB 총리NNG 에JKB 좋VA 은ETM 분NNB 을JKO 추천NNG 해XSV+EC 주VX 신다면EP+EC 그MM 분NNB 을JKO 총리NNG 로JKB 임명NNG 해XSV+EC 실질NNG 적XSN 으로JKB 내각NNG 을JKO 통할NNG 할XSV+ETM 수NNB 있VV 도록EC 하VX 겠EP 다EC 고JKQ 밝혔VV+EP 다EF 박대통령NNP 은JX 이날NNG 오전NNG 국회NNG 를JKO 전격NNG 방문NNG 정세균NNP 국회의장NNP 을JKO 만나VV+EC 최순실NNP 정국NNG 수습NNG 을JKO 위해VV+EC 국회NNG 가JKS 추천NNG 한XSA+ETM 총리NNG 를JKO 임명NNG 해XSV+EC 달VX 라는ETM 야권의요구NNP 를JKO 수용NNG 하XSV 겠EP 다는ETM 의사NNG 를JKO 공식NNG 적XSN 으로JKB 밝혔VV+EP 다EF 이NP 에JKB 따라VV+EC 박대통령NNP 은JX 지난VV+ETM 2SN 일NNBC 참여정부NNP 핵심NNG 였VCP+EP 던ETM 김병준NNP 전MM 청와대NNP 정책NNG 실장NNG 을JKO 책임NNG 총리NNG 로JKB 내정NNG 했으나XSV+EP+EC 지명NNG 6SN 일NNBC 만NNB 에JKB 사실NNG 상XSN 철회NNG 하XSV 는ETM 수순NNG 을JKO 밟VV 을ETM 것NNB 으로JKB 예상NNG 된다XSV+EF 박대통령NNP 이JKS 정기국회NNP 예산안NNG 시정NNG 연설NNG 이나JC 국회NNG 개원NNG 연설NNG 등NNB 공식NNG 일정NNG 을JKO 제외NNG 하XSV 고EC 정치NNG 적XSN 인VCP+ETM 이유NNG 로JKB 국회NNG 를JKO 방문NNG 한XSA+ETM 것NNB 은JX 이번NNG 이JKS 두MM 번NNBC 째XSN 다VCP+EF 박대통령NNP 은JX 지난VV+ETM 2013SN 년NNB 9SN 월NNBC 국정원NNP 대선NNG 개입NNG 의혹NNG 정국NNG 을JKO 풀VV 기ETN 위해VV+EC 여야NNG 대표NNG 와JC 국회NNG 사랑NNG 재NNG 에서JKB 회동NNG 한XSA+ETM 적NNB 이JKS 있VA 다EF\n"
     ]
    }
   ],
   "source": [
    "print tokenizer(inp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새MM 누리NNG 당XSN 과JC 새MM 누리NNG 당XSN 박근혜NNP 대통령NNG 은JX 8SN 일NNBC 국회NNG 에서JKB 여야NNG 합의NNG 로JKB 총리NNG 에JKB 좋VA 은ETM 분NNB 을JKO 추천NNG 해XSV+EC 주VX 신다면EP+EC 그MM 분NNB 을JKO 총리NNG 로JKB 임명NNG 해XSV+EC 실질NNG 적XSN 으로JKB 내각NNG 을JKO 통할NNG 할XSV+ETM 수NNB 있VV 도록EC 하VX 겠EP 다EC 고JKQ 밝혔VV+EP 다EF 박NNP 대통령NNG 은JX 이날NNG 오전NNG 국회NNG 를JKO 전격NNG 방문NNG 정세균NNP 국회NNG 의장NNG 을JKO 만나VV+EC 최순NNP 실NNG 정국NNG 수습NNG 을JKO 위해VV+EC 국회NNG 가JKS 추천NNG 한XSA+ETM 총리NNG 를JKO 임명NNG 해XSV+EC 달VX 라는ETM 야권NNG 의JKG 요구NNG 를JKO 수용NNG 하XSV 겠EP 다는ETM 의사NNG 를JKO 공식NNG 적XSN 으로JKB 밝혔VV+EP 다EF 이NP 에JKB 따라VV+EC 박NNP 대통령NNG 은JX 지난VV+ETM 2SN 일NNBC 참여NNG 정부NNG 핵심NNG 인사NNG 였VCP+EP 던ETM 김병준NNP 전MM 청와대NNP 정책NNG 실장NNG 을JKO 책임NNG 총리NNG 로JKB 내정NNG 했으나XSV+EP+EC 지명NNG 6SN 일NNBC 만NNB 에JKB 사실NNG 상XSN 철회NNG 하XSV 는ETM 수순NNG 을JKO 밟VV 을ETM 것NNB 으로JKB 예상NNG 된다XSV+EF 박NNP 대통령NNG 이JKS 정기NNG 국회NNG 예산안NNG 시정NNG 연설NNG 이나JC 국회NNG 개원NNG 연설NNG 등NNB 공식NNG 일정NNG 을JKO 제외NNG 하XSV 고EC 정치NNG 적XSN 인VCP+ETM 이유NNG 로JKB 국회NNG 를JKO 방문NNG 한XSA+ETM 것NNB 은JX 이번NNG 이JKS 두MM 번NNBC 째XSN 다VCP+EF 박NNP 대통령NNG 은JX 지난VV+ETM 2013SN 년NNB 9SN 월NNBC 국정원NNP 대선NNG 개입NNG 의혹NNG 정국NNG 을JKO 풀VV 기ETN 위해VV+EC 여야NNG 대표NNG 와JC 국회NNG 사랑NNG 재NNG 에서JKB 회동NNG 한XSA+ETM 적NNB 이JKS 있VA 다EF\n"
     ]
    }
   ],
   "source": [
    "print cn.tokenizer(inp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent  rank\n",
       "1       1     1\n",
       "2       2     2\n",
       "3       3     3\n",
       "4       4     4\n",
       "5       5     5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clu_rank1 = pd.DataFrame([1, 2, 3, 4, 5], [1, 2, 3, 4, 5], columns = ['parent'])\n",
    "clu_rank2 = pd.DataFrame([5, 4, 3, 2, 1], [5, 4, 3, 2, 1], columns = ['rank'])\n",
    "s1 = clu_rank1.sort_index()\n",
    "s2 = clu_rank2.sort_index()\n",
    "\n",
    "frames = [s1, s2]\n",
    "\n",
    "pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in cn.custom_pos_tags_arr(inp_str, dicts):\n",
    "    print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicts = [u'새누리', u'새누리당', u'더민주', u'더민주당', u'최순실']\n",
    "\n",
    "s = u'새누리당과 더민주 더민주당이 최순실'\n",
    "pts = cn.custom_pos(mecab.pos(inp_str), 3, dicts)\n",
    "for r in mecab.pos(s):\n",
    "    print r[0], r[1]\n",
    "print \"----\"\n",
    "# for r in mecab.pos(inp_str):\n",
    "#     print r[0], r[1]\n",
    "print \"----\"\n",
    "for r in pts:\n",
    "    print r[0], r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_text = cn.text_cleaning(inp_str)\n",
    "pos_tags = mecab.pos(clean_text)\n",
    "clean_text2 = cn.text_cleaning_without_special_ch(inp_str)\n",
    "split_by_whitespace = clean_text2.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in split_by_whitespace:\n",
    "    p = mecab.pos(s)\n",
    "    \n",
    "#     p = mecab.nouns(s)\n",
    "    for p1 in p:\n",
    "        print p1[0], p1[1]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def morphs_ngrams_without_tag(inp_pos, max_n):\n",
    "    results = []\n",
    "    for n in range(2, max_n + 1):\n",
    "        ngrams = zip(*[inp_pos[i:] for i in range(n)])\n",
    "        for ngram in ngrams:\n",
    "            if(all([not cn.test_special_ch(e[1]) for e in ngram])):\n",
    "                results.append(ngram)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = morphs_ngrams_without_tag(pos_tags,3)\n",
    "l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "term_dic = {}\n",
    "\n",
    "ngrams = morphs_ngrams_without_tag(pos_tags,3)\n",
    "counter=Counter(ngrams)\n",
    "\n",
    "tags = list(set(ngrams))\n",
    "for t in tags:\n",
    "    s = sum(1 if x == t else 0 for x in split_by_whitespace)\n",
    "    if(s > 0):\n",
    "        term_dic[t] = {\n",
    "            \"morphs\": counter[t],\n",
    "            \"split\": s\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in split_by_whitespace:\n",
    "    p = mecab.pos(s)\n",
    "#     p = mecab.nouns(s)\n",
    "    for p1 in p:\n",
    "        print p1[0], p1[1]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, val in term_dic.items():\n",
    "    print key, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = articles_data.makeDataset(crawled_collection, w2v_src_dir, corpus_path)\n",
    "print size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles_data.trainWord2Vec(w2v_src_dir, w2v_path, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = articles_data.find_recent_articles(crawled_collection, catelist_path)\n",
    "sc = SimilarityClustering()\n",
    "sc.train(\"cate\", w2v_path, train_df, path=\"../datastore\", prefix=prefix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SimilarityClustering.load(path=\"../datastore\", prefix=prefix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sc.select_model('dbow+dmm')\n",
    "# len(sc.dm_.docvecs[0])\n",
    "# sc.cluster_train(\"cate\", path=\"../datastore\", prefix=prefix_str, repeat=1, threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.select_model('dbow+dmm')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "v1 = sc.dm_.docvecs[0]\n",
    "v2 = sc.dm_.docvecs[1]\n",
    "n = len(v2)\n",
    "cs = cosine_similarity(v1.reshape(1,n), v2.reshape(1,n))[0][0]\n",
    "cs\n",
    "# sc.iner_score(0.8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.save_to_db(prefix, clusters_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sc.print_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.print_centers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters_collection.find_one({\"cluster\":1104032})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download()\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
